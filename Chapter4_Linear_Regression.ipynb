{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 Linear Regression\n",
    "\n",
    "Post-menopausal women who exercise less tend to have lower bone mineral density\n",
    "(BMD), putting them at increased risk for fractures. But they also tend to be older,\n",
    "frailer, and heavier, which may explain the association between exercise and BMD. People whose diet is high fat on average have higher low-density lipoprotein (LDL)\n",
    "cholesterol, a risk factor for CHD. But they are also more likely to smoke and be\n",
    "overweight, factors which are also strongly associated with CHD risk. Increasing\n",
    "body mass index (BMI) predicts higher levels of hemoglobin $HbA_{1c}$, a marker\n",
    "for poor control of glucose levels; however, older age and ethnic background also\n",
    "predict higher $HbA_{1c}$ .\n",
    "\n",
    "These are all examples of potentially complex relationships in observational data\n",
    "where a continuous outcome of interest, such as BMD, SBP, and $HbA_{1c}$ , is related\n",
    "to a risk factor in analyses that do not take account of other factors. But in each case\n",
    "the risk factor of interest is associated with a number of other factors, or potential\n",
    "<font color=red>confounders</font>, which also predict the outcome. So the simple association we observe\n",
    "between the factor of interest and the outcome may be explained by the other factors.\n",
    "\n",
    "Similarly, in experiments, including clinical trials, factors other than treatment\n",
    "may need to be taken into account. If the randomization is properly implemented,\n",
    "treatment assignment is on average not associated with any prognostic variable,\n",
    "so confounding is usually not an issue. However, in stratified and other complex\n",
    "study designs, multipredictor analysis is used to ensure that CIs, hypothesis tests,\n",
    "and P-values are valid. For example, it is now standard practice to account for\n",
    "clinical center in the analysis of multisite clinical trials, often using the random\n",
    "effects methodology to be introduced in Chap. 7. And with continuous outcomes,\n",
    "stratifying on a strong predictor in both design and analysis can account for a\n",
    "substantial proportion of outcome variability, increasing the efficiency of the study. Multipredictor analysis may also be used when baseline differences are apparent\n",
    "between the randomized groups, to account for potential confounding of treatment\n",
    "assignment.\n",
    "\n",
    "Another way the predictor–outcome relationship can depend on other factors\n",
    "is that an association may not be the same in all parts of the population.For\n",
    "example, hormone therapy (HT) has a smaller beneficial effect on LDL levels among\n",
    "postmenopausal women who are also taking statins, and its effect on BMD may\n",
    "be greater in younger postmenopausal women. These are examples of interaction,\n",
    "where the association of a factor of primary interest with an outcome is modified by\n",
    "another factor.\n",
    "\n",
    "The problem of sorting out complex relationships is not restricted to continuous\n",
    "outcomes; the same issues arise with the binary outcomes covered in Chap. 5,\n",
    "survival times in Chap. 6, and repeated measures in Chap. 7. A general statistical\n",
    "approach to these problems is needed. \n",
    "\n",
    "The topic of this chapter is the multipredictor linear regression model, a flexible\n",
    "and widely used tool for assessing the joint relationships of multiple predictors\n",
    "with a continuous outcome variable. We begin by illustrating some basic ideas\n",
    "in a simple example (Sect. 4.1). Then in Sect. 4.2, we present the assumptions of\n",
    "the multipredictor linear regression model and show how the simple linear model\n",
    "reviewed in Chap. 3 is extended to accommodate multiple predictors. Section 4.3\n",
    "shows how categorical predictors with multiple levels are coded and interpreted.\n",
    "Sections 4.4–4.6 describe how multipredictor regression models can be used to deal\n",
    "with confounding, mediation, and interaction, respectively. Section 4.7 introduces\n",
    "some simple methods for assessing the fit of the model to the data and how well the\n",
    "data conform to the underlying assumptions of the model. Section 4.8 introduces\n",
    "sample size, power, and minimum detectable effect calculations for the multiple\n",
    "linear model. In Chap. 9, we use a potential outcomes view of causal effects to show\n",
    "how and under what conditions multipredictor regression models might be used to\n",
    "estimate them, and in Chap. 10 we discuss the difficult problem of which variables\n",
    "and how many to include in a multipredictor model.\n",
    "\n",
    "## 4.1 Example: Exercise and Glucose\n",
    "\n",
    "Glucose levels above 125 mg/dL are diagnostic of diabetes, while levels in the range\n",
    "from 100 to 125 mg/dL signal increased risk of progressing to this serious and\n",
    "increasingly widespread condition. So it is of interest to determine whether exercise,\n",
    "a modifiable lifestyle factor, would help people reduce their glucose levels and thus\n",
    "avoid diabetes.\n",
    "\n",
    "To answer this question definitively would require a randomized clinical trial,\n",
    "a difficult and expensive undertaking. As a result, research questions like this are\n",
    "often initially looked at using observational data. But this is complicated by the fact\n",
    "that people who exercise differ in many ways from those who do not, and some of\n",
    "the other differences might explain any unadjusted association between exercise and\n",
    "glucose level.\n",
    "\n",
    "##### Load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "plt.style.use('seaborn-white')\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression as sk_lm\n",
    "from sklearn.metrics import explained_variance_score, mean_squared_error,r2_score\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load the data `Hers` and check the dimension and NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HT</th>\n",
       "      <th>age</th>\n",
       "      <th>raceth</th>\n",
       "      <th>nonwhite</th>\n",
       "      <th>smoking</th>\n",
       "      <th>drinkany</th>\n",
       "      <th>exercise</th>\n",
       "      <th>physact</th>\n",
       "      <th>globrat</th>\n",
       "      <th>poorfair</th>\n",
       "      <th>...</th>\n",
       "      <th>LDL</th>\n",
       "      <th>HDL</th>\n",
       "      <th>TG</th>\n",
       "      <th>tchol1</th>\n",
       "      <th>LDL1</th>\n",
       "      <th>HDL1</th>\n",
       "      <th>TG1</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>age10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>placebo</td>\n",
       "      <td>70</td>\n",
       "      <td>African American</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>much more active</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>122.400002</td>\n",
       "      <td>52.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>137.600006</td>\n",
       "      <td>48.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>138</td>\n",
       "      <td>78.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>placebo</td>\n",
       "      <td>62</td>\n",
       "      <td>African American</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>much less active</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>241.600006</td>\n",
       "      <td>44.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>150.600006</td>\n",
       "      <td>48.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>118</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hormone therapy</td>\n",
       "      <td>69</td>\n",
       "      <td>White</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>about as active</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>166.199997</td>\n",
       "      <td>57.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>134</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>placebo</td>\n",
       "      <td>64</td>\n",
       "      <td>White</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>much less active</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>116.199997</td>\n",
       "      <td>56.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>122.599998</td>\n",
       "      <td>57.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>152</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>placebo</td>\n",
       "      <td>65</td>\n",
       "      <td>White</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>somewhat less active</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>150.600006</td>\n",
       "      <td>42.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>172.199997</td>\n",
       "      <td>35.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>175</td>\n",
       "      <td>95.0</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                HT  age            raceth nonwhite smoking drinkany exercise  \\\n",
       "0          placebo   70  African American      yes      no       no       no   \n",
       "1          placebo   62  African American      yes      no       no       no   \n",
       "2  hormone therapy   69             White       no      no       no       no   \n",
       "3          placebo   64             White       no     yes      yes       no   \n",
       "4          placebo   65             White       no      no       no       no   \n",
       "\n",
       "                physact globrat poorfair  ...           LDL   HDL     TG  \\\n",
       "0      much more active    good       no  ...    122.400002  52.0   73.0   \n",
       "1      much less active    good       no  ...    241.600006  44.0  107.0   \n",
       "2       about as active    good       no  ...    166.199997  57.0  154.0   \n",
       "3      much less active    good       no  ...    116.199997  56.0  159.0   \n",
       "4  somewhat less active    good       no  ...    150.600006  42.0  107.0   \n",
       "\n",
       "  tchol1        LDL1  HDL1    TG1  SBP   DBP  age10  \n",
       "0  201.0  137.600006  48.0   77.0  138  78.0    7.0  \n",
       "1  216.0  150.600006  48.0   87.0  118  70.0    6.2  \n",
       "2  254.0  156.000000  66.0  160.0  134  78.0    6.9  \n",
       "3  207.0  122.599998  57.0  137.0  152  72.0    6.4  \n",
       "4  235.0  172.199997  35.0  139.0  175  95.0    6.5  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hers=pd.read_stata('./Data/Chapter4/hersdata.dta')\n",
    "hers.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2763, 37)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HT            0\n",
       "age           0\n",
       "raceth        0\n",
       "nonwhite      0\n",
       "smoking       0\n",
       "drinkany      2\n",
       "exercise      0\n",
       "physact       0\n",
       "globrat       3\n",
       "poorfair      3\n",
       "medcond       0\n",
       "htnmeds       0\n",
       "statins       0\n",
       "diabetes      0\n",
       "dmpills       0\n",
       "insulin       0\n",
       "weight        2\n",
       "BMI           5\n",
       "waist         2\n",
       "WHR           3\n",
       "glucose       0\n",
       "weight1     150\n",
       "BMI1        153\n",
       "waist1      151\n",
       "WHR1        151\n",
       "glucose1    150\n",
       "tchol         4\n",
       "LDL          11\n",
       "HDL          11\n",
       "TG            4\n",
       "tchol1      150\n",
       "LDL1        155\n",
       "HDL1        155\n",
       "TG1         150\n",
       "SBP           0\n",
       "DBP           1\n",
       "age10         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hers.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     2032\n",
       "yes     731\n",
       "Name: diabetes, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hers.diabetes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     1695\n",
       "yes    1068\n",
       "Name: exercise, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hers.exercise.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 4.1 Unadjusted regression of glucose on exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                glucose   R-squared:                       0.007\n",
      "Model:                            OLS   Adj. R-squared:                  0.007\n",
      "Method:                 Least Squares   F-statistic:                     14.97\n",
      "Date:                Fri, 25 Jan 2019   Prob (F-statistic):           0.000113\n",
      "Time:                        08:55:04   Log-Likelihood:                -7502.4\n",
      "No. Observations:                2032   AIC:                         1.501e+04\n",
      "Df Residuals:                    2030   BIC:                         1.502e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept          97.3610      0.282    345.848      0.000      96.809      97.913\n",
      "exercise[T.yes]    -1.6928      0.438     -3.868      0.000      -2.551      -0.835\n",
      "==============================================================================\n",
      "Omnibus:                       52.779   Durbin-Watson:                   1.933\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               56.849\n",
      "Skew:                           0.384   Prob(JB):                     4.52e-13\n",
      "Kurtosis:                       3.286   Cond. No.                         2.46\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "glureg=smf.ols('glucose~exercise', data=hers, subset=hers['diabetes']=='no').fit()\n",
    "print(glureg.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table 4.1 shows a simple linear model using a measure of exercise to predict\n",
    "baseline glucose levels among 2,032 participants without diabetes in the HERS clinical trial of hormone therapy (HT) (Hulley et al. 1998). Women with diabetes\n",
    "are excluded because the research question is whether exercise might help to prevent\n",
    "progression to diabetes among women at risk, and because the causal determinants\n",
    "of glucose may be different in that group. Furthermore, glucose levels are far more\n",
    "variable among diabetics, a violation of the assumption of homoscedasticity, as we\n",
    "show in Sect. 4.7.3 below. <font color=red>The coefficient estimate (coef.) for exercise shows\n",
    "that average baseline glucose levels were about $1.7mg/dL$ lower among women who\n",
    "exercised at least three times a week than among women who exercised less. This\n",
    "difference is statistically significant ($t=-3.87;P < 0:0005$).</font>\n",
    "    \n",
    "However, women who exercise are slightly younger, a little more likely to use\n",
    "alcohol, and in particular have lower average BMI, all factors associated with\n",
    "glucose levels. This implies that the lower average glucose we observe among\n",
    "women who exercise could be due at least in part to differences in these other\n",
    "predictors. Under these conditions, it is important that our estimate of the difference\n",
    "in average glucose levels associated with exercise be “adjusted” for the effects\n",
    "of these potential confounders of the unadjusted association. Ideally, adjustment\n",
    "using a multipredictor regression model provides an estimate of the causal effect\n",
    "of exercise on average glucose levels, by holding the other variables constant. In\n",
    "Chap. 9, the rationale for estimation of causal effects using multipredictor regression\n",
    "models is explained in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                glucose   R-squared:                       0.072\n",
      "Model:                            OLS   Adj. R-squared:                  0.070\n",
      "Method:                 Least Squares   F-statistic:                     39.22\n",
      "Date:                Fri, 25 Jan 2019   Prob (F-statistic):           1.14e-31\n",
      "Time:                        08:55:04   Log-Likelihood:                -7416.8\n",
      "No. Observations:                2028   AIC:                         1.484e+04\n",
      "Df Residuals:                    2023   BIC:                         1.487e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "Intercept          78.9624      2.593     30.454      0.000      73.877      84.047\n",
      "exercise[T.yes]    -0.9504      0.429     -2.217      0.027      -1.791      -0.110\n",
      "drinkany[T.yes]     0.6803      0.422      1.612      0.107      -0.147       1.508\n",
      "age                 0.0635      0.031      2.024      0.043       0.002       0.125\n",
      "BMI                 0.4892      0.042     11.774      0.000       0.408       0.571\n",
      "==============================================================================\n",
      "Omnibus:                       52.836   Durbin-Watson:                   1.922\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               58.944\n",
      "Skew:                           0.362   Prob(JB):                     1.59e-13\n",
      "Kurtosis:                       3.415   Cond. No.                         905.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "glures=smf.ols('glucose~exercise+age+drinkany+BMI', data=hers, subset=hers['diabetes']=='no').fit()\n",
    "print(glures.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Table 4.2, we see that in a multiple regression model that also includes—\n",
    "that is, adjusts for—age, alcohol use (drinkany), and BMI, average glucose is\n",
    "estimated to be only about $1mg/dL$ lower among women who exercise ($95\\%~ CI ~0.1–\n",
    "1.8, P=0.027$), holding the other three factors constant. The multipredictor model\n",
    "also shows that average glucose levels are about 0.7mg/dL higher among alcohol\n",
    "users than among nonusers. Average levels also increase by about $0.5mg/dL$ per unit\n",
    "increase in BMI, and by $0.06mg/dL$ for each additional year of age. Each of these\n",
    "associations is statistically significant after adjustment for the other predictors in\n",
    "the model. Furthermore, the association of each of the four predictors with glucose\n",
    "levels is adjusted for the effects of the other three, in the sense of taking account of\n",
    "its correlation with the other predictors and their adjusted associations with glucose levels. \n",
    "\n",
    "In summary, the multipredictor model for glucose levels shows that the\n",
    "unadjusted association between exercise and glucose is partly but not completely\n",
    "explained by BMI, age, and alcohol use, and that exercise remains a statistically\n",
    "significant predictor of glucose levels after adjustment for these three other factors—\n",
    "that is, when they are held constant by the multipredictor regression model.\n",
    "\n",
    "Still, we have been careful to retain the language of association rather than cause\n",
    "and effect, and in Chaps. 9 and 10 will suggest that adjustment for additional potential\n",
    "confounders would be needed before we could consider a causal interpretation\n",
    "of the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Multiple Linear Regression Model\n",
    "Confounding thus motivates models in which the average value of the outcome is\n",
    "allowed to depend on multiple predictors instead of just one. Many basic elements\n",
    "of the multiple linear model carry over from the simple linear model, which was\n",
    "reviewed in Sect. 3.3. In Sect. 9.1, we show how this model is potentially suited to\n",
    "estimating causal relationships between predictors and outcomes.\n",
    "\n",
    "### 4.2.1 Systematic Part of the Model\n",
    "\n",
    "For the simple linear model with a single predictor, the regression line is defined by\n",
    "\n",
    "\\begin{equation*} \n",
    "\\begin{split}\n",
    "E[y\\mid x]&=\\text{average value of outcome y given predictor value x}\\\\\n",
    "&=\\beta_0+\\beta_1 x\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "In the multiple regression model, this generalizes to\n",
    "\\begin{equation*}\n",
    "E[y\\mid x]=\\beta_0+\\beta_1 x_1+\\beta_2 x_2+\\cdots+\\beta_px_p \\tag{4.2}\n",
    "\\end{equation*} \n",
    "where $x$ represents the collection of $p$ predictors $x_1, x_2, \\dots, x_p$ in the model, and $\\beta_1, \\beta_2, \\dots, \\beta_p$ are the corresponding regression coefficients. \n",
    "\n",
    "The right-hand side of model has a relatively simple form, <font color=red>a linear\n",
    "combination of the predictors and coefficients.</font> Analogous linear combinations of\n",
    "predictors and coefficients, often referred to as the linear predictor, are used in\n",
    "all the other regression models covered in this book. Despite the simple form of\n",
    "(4.2), the multipredictor linear regression model is a flexible tool, and with the\n",
    "elaborations to be introduced later in this chapter, usually allows us to representwith\n",
    "considerable realism how the average value of the outcome varies systematically\n",
    "with the predictors. In Sect. 4.7, we will consider methods for examining the\n",
    "adequacy of this part of the model and for improving it.\n",
    "\n",
    "#### Interpretation of Adjusted Regression Coefficients\n",
    "In (4.2), the coefficient $\\beta_j, j=1,\\dots,p$ gives <font color=red>the change in $E[y\\mid x]$ for an increase\n",
    "of one unit in predictor $x_j$, holding other factors in the model constant</font>; each of the estimates is adjusted for the effects of all the other predictors. As in the simple linear\n",
    "model, the intercept $\\beta_0$ gives the value of $E[y\\mid x]$ when all the predictors are equal to\n",
    "zero; 'centering' of the continuous predictors can make the intercept interpretable. If confounding has been persuasively ruled out, we may be willing to interpret the\n",
    "adjusted coefficient estimates as representing causal effects.\n",
    "\n",
    "### 4.2.2 Random Part of the Model\n",
    "As before, individual observations of the outcome $y_i$ are modeled as varying by an\n",
    "error term $\\varepsilon_i$ about an average determined by their predictor values $x_i$:\n",
    "\\begin{equation*}\n",
    "\\begin{split}\n",
    "y_i&=e[y_i\\mid x_i]+\\varepsilon\\\\\n",
    "&=\\beta_0+\\beta_1x_{1i}+\\beta_2x_{2i}+\\cdots+\\beta_p x_{pi}+\\varepsilon_i\n",
    "\\end{split}\n",
    "\\end{equation*}\n",
    "where $X_{ji}$ is the value of predictor variable $x_j$ for observation $i$. We again assume\n",
    "that $\\varepsilon \\sim i.i.d \\mathscr{N} (0, \\sigma^2_{\\varepsilon})$; that is, $\\varepsilon$ is normally distributed with mean zero and the\n",
    "same standard deviation $\\sigma_\\varepsilon$ at every value of $x$, and that its values are statistically\n",
    "independent.\n",
    "\n",
    "#### Fitted Values, Sums of Squares, and Variance Estimators\n",
    "From (4.2), it is clear that the fitted values $\\hat{y}_i$, defined for the simple linear model in\n",
    "(3.4), now depend on all p predictors and the corresponding regression coefficient\n",
    "estimates, rather than just one predictor and two coefficients. The resulting sums of\n",
    "squares and variance estimators introduced in Sect. 3.3 are otherwise unchanged in\n",
    "the multipredictor model.\n",
    "\n",
    "#### Variance of Adjusted Regression Coefficients\n",
    "Including multiple predictors does affect the variance of $\\hat{\\beta}_j$, which now depends on\n",
    "an additional factor $r_j$, the multiple correlation of $x_j$ with the other predictors in the\n",
    "model. Specifically,\\begin{equation}\n",
    "Var(\\hat{\\beta}_j)=\\dfrac{\\sigma^2_{y\\mid x}}{(n-1)\\sigma^2_{x_j}(1-r^2_j)} \\tag{4.4}\n",
    "\\end{equation}\n",
    "where, as before, $\\sigma^2_{y\\mid x}$ is the residual variance of the outcome and $\\sigma^2_{x_j}$ is the variance\n",
    "of $x_j$; $r_j$ is equivalent to $r=\\sqrt{R^2}$ from a multiple linear model in which $x_j$ is regressed on all the other predictors. The term $1/(1-r_j^2)$ is known as the <font color=DodgerBlue> variance inflation factor (IMF)</font>, since $Var(\\hat{\\beta}_j)$ is increased to the extent that $x_j$ is correlated with other predictors in the model.\n",
    "\n",
    "However, inclusion of other predictors, especially powerful ones, also tends to decrease $\\sigma^2_{y\\mid x}$, the residual or unexplained variance of the outcome. Thus, the overall impact of including other predictors on $Var(\\hat{\\beta}_j)$ depends on both the correlation of $x_j$ with the other predictors and how much additional variability they explain. In the glucose example, the standard error of the coefficient estimate for exercise declines\n",
    "slightly, from 0.44 to 0.43, after adjustment for age, alcohol use, and BMI. This\n",
    "reflects the reduction in residual standard deviation previously described, as well as\n",
    "a variance inflation factor in the adjusted model of only 1.03.\n",
    "\n",
    "#### t-Tests and Confidence Intervals\n",
    "The t -tests of the null hypothesis $H_0: \\beta_j=0$ and CIs for $\\beta_j$ carry over almost unchanged for each of the $\\beta_s$ estimated by the model, only using (4.4) rather than (3.11) to compute the standard error of the regression coefficient, and comparing the\n",
    "t -statistic to a t -distribution with $n-(p+1)$ degrees of freedom (p is the number of predictors in the model, and and an extra degree of freedom is used in estimation of\n",
    "the intercept $\\beta_0$).\n",
    "\n",
    "However, there is a substantial difference in interpretation, since the results are\n",
    "now adjusted for other predictors. Thus in rejecting the null hypothesis $H_0: \\beta_j=0$ we would be making the stronger claim that, in the population $x_j$ predicts $y$, holding the other factors in the model constant. Similarly, the CI for $\\beta_j$ refers to the parameter wich takes account of the other $p-1$ predictors in the model.\n",
    "\n",
    "We have just seen that $Var(\\hat{\\beta}_j)$ may not be increased by adjustment. However, in\n",
    "Sect. 4.4 we will see that including other predictors in order to control confounding\n",
    "commonly has the effect of attenuating the unadjusted estimate of the association\n",
    "of $x_j$ with $y$. This reflects the fact that the population parameter being estimated\n",
    "in the adjusted model is often closer to zero than the parameter estimated in the\n",
    "unadjusted model, since some of the unadjusted association is explained by other\n",
    "predictors. If this is the case, then even if $Var(\\hat{\\beta}_j)$ is unchanged, it may be more difficult to reject $H_0:\\beta_j=0$ in the adjusted model. In the glucose example, the\n",
    "adjusted coefficient estimate for exercise is considerably smaller than the unadjusted\n",
    "estimate. As a result the t -statistic is reduced from-3.87 to -2.22—still statistically\n",
    "significant, but less highly so.\n",
    "\n",
    "### 4.2.3 Generalization of $R^2$ and r\n",
    "\n",
    "The coefficient of determination $R^2=\\dfrac{MSS}{TSS}$ retains its interpretation as <font color=red>the\n",
    "proportion of the total variability of the outcome that can be accounted for by the\n",
    "predictor variables.</font> Under themodel, the fitted values summarize all the information\n",
    "that the predictors supply about the outcome. Thus, the multiple correlation\n",
    "coefficient $r=\\sqrt{R^2}$ now represents <font color=red>the correlation between the outcome y and the\n",
    "fitted values $\\hat{y}$.</font> It is easy to confirm this identity by extracting the fitted values from\n",
    "a regression model and computing their correlation with the outcome (Problem 4.3). In the glucose example, $R^2$ increases from less than $1\\%$ in the unadjusted model to\n",
    "$7\\%$ after inclusion of age, alcohol use, and BMI, a substantial increase in relative if\n",
    "not absolute terms.\n",
    "\n",
    "### 4.2.4 Standardized Regression Coefficients\n",
    "\n",
    "In Sect. 3.3.9, we saw that the slope coefficient $\\beta_1$ in a simple linear model is\n",
    "systematically related to the Pearson correlation coefficient (3.12); specifically, $r=\\beta_1\\frac{\\sigma_x}{\\sigma_y}$, where $\\sigma_x$ and $\\sigma_y$ are the standard deviations of the predictor and\n",
    "outcome. Moreover, we pointed out that the scale-free correlation coefficient makes\n",
    "it easier to compare the strength of association between the outcome and various\n",
    "predictors across single-predictor models. In the context of a multipredictor model, <font color=DodgerBlue> standardized regression coefficients </font> play this role. The standardized regression coefficient $\\beta_j^s$ for predictor $x_j$ is defined in analogy to (3.12) as $$\n",
    "\\beta_j^s=\\beta_j \\dfrac{\\sigma_{x_j}}{\\sigma_y}, \\tag{4.5}$$ where $\\sigma_x$ and $\\sigma_y$ are the standard deviations of predictor $x_j$ and the outcome $y$. <font color=red> These standardized coefficient estimates are what would be obtained from the\n",
    "regression if the outcome and all the predictors were first rescaled to have standard\n",
    "deviation 1. </font> Thus, they give the change in standard deviation units in the average\n",
    "value of $y$ per standard deviation increase in the predictor. Standardized coefficients\n",
    "make it easy to compare the strength of association of different continuous\n",
    "predictors with the outcome within the same model.\n",
    "\n",
    "For binary predictors, however, the unstandardized regression coefficients may\n",
    "be more directly interpretable than the standardized estimates, since the unstandardized\n",
    "coefficients for such predictors simply estimate the differences in the average\n",
    "value of the outcome between the two groups defined by the predictor, holding the\n",
    "other predictors in the model constant.\n",
    "\n",
    "## 4.3 Categorical Predictors\n",
    "\n",
    "In Chap. 3, the simple regression model was introduced with a single continuous\n",
    "predictor. However, predictors in both simple and multipredictor regression models\n",
    "can be binary, categorical, or discrete numeric, as well as continuous numeric.\n",
    "\n",
    "### 4.3.1 Binary Predictors\n",
    "The exercise variable in the model for LDL levels shown in Table 4.1 is an example\n",
    "of a binary predictor. A good way to code such a variable is as an indicator or dummy\n",
    "variable, taking the value 1 for the group with the characteristic of interest, and 0\n",
    "for the group without the characteristic. With this coding, the regression coefficient\n",
    "corresponding to this variable has a straightforward interpretation as the increase or\n",
    "decrease in average outcome levels in the group with the characteristic, with respect\n",
    "to the reference group. \n",
    "\n",
    "To see this, consider the simple regression model for average glucose values: \\begin{equation}\n",
    "E[\\text{glucose}\\mid x]=\\beta_0+\\beta_1\\text{exercise} \\tag{4.6}\n",
    "\\end{equation}\n",
    "With the indicator coding of exercise (1 D yes, 0 D no), the average value of\n",
    "glucose is $\\beta_0+\\beta_1$ among women who do exercise, and $\\beta_0$ among the rest. It follows directly that $\\beta_1$ is the difference in average glucose levels between the two groups. This is consistent with our more general definition of $\\beta_j$ as <font color=red> the change in $E[y\\mid x]$ for a one unit increase in $x_j$.</font> Furthermore, the t -test of the null hypothesis $H_0: \\beta_1=0$ is a test of whether the between-group difference in average glucose levels differs\n",
    "from zero. In fact, this unadjusted model is equivalent to a t -test comparing glucose\n",
    "levels in women who do and do not exercise. A final point: when coded this way, the\n",
    "average value of the exercise variable gives the proportion of women who exercise.\n",
    "\n",
    "A commonly used alternative coding for binary variables is (1= yes, 2 = no).\n",
    "With this coding, the coefficient $\\beta_1$ retains its interpretation as the between-group\n",
    "difference in average glucose levels, but now among women who do not exercise as\n",
    "compared to those who do, a less intuitive way to think of the difference. Furthermore,\n",
    "with this coding the coefficient $\\beta_0$ has no straightforward interpretation, and\n",
    "the average value of the binary variable is not equal to the proportion of the sample\n",
    "in either group. However, overall model fit, including fitted values of the outcome,\n",
    "standard errors, and P-values, are the same with either coding (Problem 4.1).\n",
    "\n",
    "### 4.3.2 Multilevel Categorical Predictors\n",
    "\n",
    "The 2,763 women in the HERS cohort also responded to a question about how\n",
    "physically active they considered themselves compared to other women their age.\n",
    "The five-level response variable physact ranged from “much less active” to\n",
    "“much more active,” and was coded in order from 1 to 5. This is an example of\n",
    "an ordinal variable, as described in Chap. 2, with categories that are meaningfully\n",
    "ordered, but separated by increments that may not be accurately reflected in the\n",
    "numerical codes used to represent them. For example, responses “much less active”\n",
    "and “somewhat less active” may represent a larger difference in physical activity\n",
    "than “somewhat less active” and “about as active.”\n",
    "\n",
    "Multilevel categorical variables can also be nominal, in the sense that there is\n",
    "no intrinsic ordering in the categories. Examples include ethnicity, marital status,\n",
    "occupation, and geographic region. With nominal variables, it is even clearer that\n",
    "the numeric codes often used to represent the variable in the database cannot be\n",
    "treated like the values of a numeric variable such as glucose.\n",
    "\n",
    "Categories are usually set up to be mutually exclusive and exhaustive, so that\n",
    "every member of the population falls into one and only one category. In that case,\n",
    "both ordinal and nominal categories define subgroups of the population.\n",
    "\n",
    "Both types of categorical variables are easily accommodated in multipredictor\n",
    "linear and other regression models, using indicator or dummy variables. As with\n",
    "binary variables, where two categories are represented in the model by a single\n",
    "indicator variable, categorical variables with $K\\geq 2$ levels are represented by $K-1$ indicators, one for each of level of the variable except a baseline or reference level.\n",
    "Suppose level 1 is chosen as the baseline level. Then, for $k=2,3, \\dots, K,$ indicator\n",
    "variable k has value 1 for observations belonging to the category k, and 0 for\n",
    "observations belonging to any of the other categories. Note that for $K=2$, this also describes the binary case, in which the “no” response defines the baseline or\n",
    "reference group and the indicator variable takes on value 1 only for the “yes” group.\n",
    "\n",
    "Following the Python pandas `get_dummies()` for the naming of the\n",
    "four indicator variables, Table 4.3 shows the values of the four indicator variables\n",
    "corresponding to the five response levels of physact. Each level of physact is\n",
    "defined by a unique pattern in the four indicator variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HT</th>\n",
       "      <th>age</th>\n",
       "      <th>raceth</th>\n",
       "      <th>nonwhite</th>\n",
       "      <th>smoking</th>\n",
       "      <th>drinkany</th>\n",
       "      <th>exercise</th>\n",
       "      <th>physact</th>\n",
       "      <th>globrat</th>\n",
       "      <th>poorfair</th>\n",
       "      <th>...</th>\n",
       "      <th>HDL</th>\n",
       "      <th>TG</th>\n",
       "      <th>tchol1</th>\n",
       "      <th>LDL1</th>\n",
       "      <th>HDL1</th>\n",
       "      <th>TG1</th>\n",
       "      <th>SBP</th>\n",
       "      <th>DBP</th>\n",
       "      <th>age10</th>\n",
       "      <th>i.physact</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>placebo</td>\n",
       "      <td>70</td>\n",
       "      <td>African American</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>much more active</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>137.600006</td>\n",
       "      <td>48.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>138</td>\n",
       "      <td>78.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.physact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>placebo</td>\n",
       "      <td>62</td>\n",
       "      <td>African American</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>much less active</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>150.600006</td>\n",
       "      <td>48.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>118</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.physact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hormone therapy</td>\n",
       "      <td>69</td>\n",
       "      <td>White</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>about as active</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>57.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>66.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>134</td>\n",
       "      <td>78.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>3.physact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>placebo</td>\n",
       "      <td>64</td>\n",
       "      <td>White</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>much less active</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>122.599998</td>\n",
       "      <td>57.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>152</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1.physact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>placebo</td>\n",
       "      <td>65</td>\n",
       "      <td>White</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>somewhat less active</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>42.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>172.199997</td>\n",
       "      <td>35.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>175</td>\n",
       "      <td>95.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.physact</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                HT  age            raceth nonwhite smoking drinkany exercise  \\\n",
       "0          placebo   70  African American      yes      no       no       no   \n",
       "1          placebo   62  African American      yes      no       no       no   \n",
       "2  hormone therapy   69             White       no      no       no       no   \n",
       "3          placebo   64             White       no     yes      yes       no   \n",
       "4          placebo   65             White       no      no       no       no   \n",
       "\n",
       "                physact globrat poorfair    ...       HDL     TG tchol1  \\\n",
       "0      much more active    good       no    ...      52.0   73.0  201.0   \n",
       "1      much less active    good       no    ...      44.0  107.0  216.0   \n",
       "2       about as active    good       no    ...      57.0  154.0  254.0   \n",
       "3      much less active    good       no    ...      56.0  159.0  207.0   \n",
       "4  somewhat less active    good       no    ...      42.0  107.0  235.0   \n",
       "\n",
       "         LDL1  HDL1    TG1  SBP   DBP  age10  i.physact  \n",
       "0  137.600006  48.0   77.0  138  78.0    7.0  5.physact  \n",
       "1  150.600006  48.0   87.0  118  70.0    6.2  1.physact  \n",
       "2  156.000000  66.0  160.0  134  78.0    6.9  3.physact  \n",
       "3  122.599998  57.0  137.0  152  72.0    6.4  1.physact  \n",
       "4  172.199997  35.0  139.0  175  95.0    6.5  2.physact  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hers['physact']=hers['physact'].astype('category')\n",
    "hers['i.physact']=hers['physact'].astype('category')\n",
    "hers['i.physact'].cat.categories=['1.physact','2.physact','3.physact','4.physact','5.physact']\n",
    "hers.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Table 4.3 Coding of indicators for a multilevel categorical variable\n",
    "<font color=red> Come back later</font>\n",
    "\n",
    "Furthermore, the corresponding $\\beta_s$ have a straightforward interpretation. For the\n",
    "moment, consider a simple regression model in which the five levels of physact\n",
    "are the only predictors. Then, \\begin{equation}\n",
    "E[\\text{glucose}\\mid x]=\\beta_0+\\beta_2 \\text{2.physact}+\\cdots+\\beta_5\\text{5.physact} \\tag{4.7}\n",
    "\\end{equation}\n",
    "\n",
    "For clarity, the $\\beta_s$ in (4.7) are indexed in accord with the levels of physact, so $\\beta_1$ does not appear in the model. Letting the four indicators take on values of $0$ or $1$ as appropriate for the five groups defined by physact, we obtain\n",
    "\\begin{equation}\n",
    "E[\\text{glucose}\\mid x]=\\begin{cases}\n",
    "\\beta_0 & physact=1\\\\\n",
    "\\beta_0+\\beta_2 & physact=2\\\\\n",
    "\\beta_0+\\beta_3 & physact=3\\\\\n",
    "\\beta_0+\\beta_4 & physact=4\\\\\n",
    "\\beta_0+\\beta_5 & physact=5\n",
    "\\end{cases}\\tag{4.8}\n",
    "\\end{equation}\n",
    "From (4.8), it is clear that the intercept $\\beta_0$ gives <font color=red>the value of $E[\\text{glucose}\\mid x]$ in the reference or much less active group (physact=1)</font>. Then it is just a matter of\n",
    "subtracting the first line of (4.8) from the second to see that $\\beta_2$ gives <font color=red>the difference in the average glucose in the somewhat less active group (physact=2) as compared\n",
    "to the much less active group</font>. Accordingly, the t-test of $H_0: \\beta_2=0$ is a test of whether average glucose levels are the same in the much less and somewhat less active groups (physact=1 and 2). And similarly for $\\beta_3, \\beta_4$, and $\\beta_5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.4 Multiple Pairwise Comparisons Between Categories\n",
    "\n",
    "### 4.3.5 Testing for Trend Across Categories\n",
    "\n",
    "#### Departures from Linear Trend\n",
    "\n",
    "## 4.4 Confounding\n",
    "\n",
    "### 4.4.1 Range of Confounding Patterns\n",
    "\n",
    "### 4.4.2 Confounding Is Difficult to Rule Out\n",
    "\n",
    "### 4.4.3 Adjusted Versus Unadjusted $\\hat{\\beta}$s\n",
    "\n",
    "### 4.4.4 Example: BMI and LDL\n",
    "\n",
    "## 4.5 Mediation\n",
    "\n",
    "### 4.5.1 Indirect Effects via the Mediator\n",
    "\n",
    "### 4.5.2 Overall and Direct Effects\n",
    "\n",
    "### 4.5.3 Percent Explained\n",
    "\n",
    "### 4.5.4 Example: BMI, Exercise, and Glucose\n",
    "\n",
    "### 4.5.5 Pitfalls in Evaluating Mediation\n",
    "\n",
    "#### Temporality\n",
    "\n",
    "#### Problems with PE\n",
    "\n",
    "## 4.6 Interaction\n",
    "\n",
    "### 4.6.1 Example: Hormone Therapy and Statin Use\n",
    "\n",
    "### 4.6.2 Example: BMI and Statin Use\n",
    "\n",
    "### 4.6.3 Interaction and Scale\n",
    "\n",
    "### 4.6.4 Example: Hormone Therapy and Baseline LDL\n",
    "\n",
    "### 4.6.5 Details\n",
    "\n",
    "## 4.7 Checking Model Assumptions and Fit\n",
    "\n",
    "### 4.7.1 Linearity\n",
    "\n",
    "#### Component-Plus-Residual Plots\n",
    "\n",
    "#### Smooth Transformations of the Predictors\n",
    "\n",
    "#### Restricted Cubic Splines\n",
    "\n",
    "#### Categorizing the Predictor\n",
    "\n",
    "#### Nonlinearity, Interaction, and Covariate Overlap\n",
    "\n",
    "### 4.7.2 Normality\n",
    "\n",
    "#### Residual Plots\n",
    "\n",
    "#### Testing for Departures from Normality\n",
    "\n",
    "#### Normalizing Transformations of the Outcome\n",
    "\n",
    "#### Alternatives to Transformation: Bootstrap and GLMs\n",
    "\n",
    "### 4.7.3 Constant Variance\n",
    "\n",
    "#### Residual Plots\n",
    "\n",
    "#### Subsample Variances\n",
    "\n",
    "#### Testing for Departures from Constant Variance\n",
    "\n",
    "#### When Departures May Cause Trouble\n",
    "\n",
    "#### Variance-Stabilizing Outcome Transformations\n",
    "\n",
    "#### Robust Standard Errors\n",
    "\n",
    "#### GLMs\n",
    "\n",
    "### 4.7.4 Outlying, High Leverage, and Influential Points\n",
    "\n",
    "#### DFBETAs\n",
    "\n",
    "#### Addressing Influential Points\n",
    "\n",
    "### 4.7.5 Interpretation of Results for Log Transformed Variables\n",
    "\n",
    "#### Log Transformation of the Predictor\n",
    "\n",
    "#### Log Transformation of the Outcome\n",
    "\n",
    "#### Log Transformation of Both Predictor and Outcome\n",
    "\n",
    "### 4.7.6 When to Use Transformations\n",
    "\n",
    "## 4.8 Sample Size, Power, and Detectable Effects\n",
    "\n",
    "### 4.8.1 Calculations Using Standard Errors Based on Published Data\n",
    "\n",
    "## 4.9 Summary\n",
    "\n",
    "## 4.11 Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
